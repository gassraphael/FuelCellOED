{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import all relevant dependencies",
   "id": "21fd87429ce55096"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:40:30.167346Z",
     "start_time": "2025-12-10T17:40:26.763707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from src.minimizer.minimizer_library.differential_evolution_save import DifferentialEvolutionParallel\n",
    "from src.visualization.plotting_functions import *\n",
    "from src.visualization.plotting_convergence import *\n",
    "from src.statistical_models.statistical_model_library.fcs_gaussian_noise_model import FCSGaussianNoiseModel\n",
    "from src.utils.experiment_serialization import import_all_experiments, import_experiment_results\n",
    "from src.math_utils.experiment_metrics import evaluate_full_metrics\n",
    "from src.model.hahn_stack_model import HahnStackModel\n",
    "from src.math_utils.derivatives.numeric_derivative_calculator import NumericDerivativeCalculator\n",
    "from src.model.parameter_set.hahn_parameter_set import HahnParameterSet\n",
    "from src.math_utils.scaler.hahn_parameter_scaler import HahnParameterScaler"
   ],
   "id": "de3f21e6cfd0b57c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define the Experiment Metadata\n",
    "- bounds for the free parameters\n",
    "- operating conditions\n",
    "- experiment repetitions\n",
    "- true parameter set\n",
    "- Experiment variance\n",
    "- current values\n",
    "\n",
    "Naming:\n",
    "unscaled/ rescaled: actual physical values\n",
    "scaled: scaled value between 0 & 1"
   ],
   "id": "fc2abc3febf22b9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:29:55.672462Z",
     "start_time": "2025-12-10T17:29:55.642783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"../data/config/reduced_example_config_workflow.yaml\"\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "number_designs = config[\"number_designs\"] #Amount of LH Designs\n",
    "n_rep = config[\"n_rep\"] #Amount of experiment repetitions\n",
    "n_current_values = config[\"n_current_values\"] #Amount of individual current values\n",
    "sigma = config[\"sigma\"] #experiment variance (10mV variance in repeated experiments)\n",
    "\n",
    "# lower and upper bounds for operating conditions\n",
    "upper_bounds_operating_conditions = np.array(config[\"upper_bounds_operating_conditions\"])\n",
    "lower_bounds_operating_conditions = np.array(config[\"lower_bounds_operating_conditions\"])\n",
    "\n",
    "I_S_array = np.linspace(1, 600, n_current_values) # initialize applicable current array request\n",
    "\n",
    "# select parameter values and names to be analyzed\n",
    "unscaled_theta_true = np.array([list(HahnParameterSet().free_parameters.values())[i] for i in [1, 2, 4]])\n",
    "names_theta = [list(HahnParameterSet().free_parameters.keys())[i] for i in [1, 2, 4]]\n",
    "\n",
    "# initialize lower and upper bounds for free parameter values\n",
    "unscaled_upper_bounds_free_params = np.array(config[\"unscaled_upper_bounds_free_params\"], dtype=float)\n",
    "unscaled_lower_bounds_free_params = np.array(config[\"unscaled_lower_bounds_free_params\"], dtype=float)\n",
    "\n",
    "print(names_theta, unscaled_lower_bounds_free_params, unscaled_theta_true, unscaled_upper_bounds_free_params)"
   ],
   "id": "9384a2ffad5ee359",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j_0_ref', 'r_el', 'D_GDL_ref'] [1.e+01 1.e-06 1.e-06] [2.1308e+03 4.2738e-06 8.6266e-06] [5.e+03 1.e-03 1.e-05]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define Scaler and scale parameter values as well as  bounds of operating conditions and parameters\n",
    "Scalers are saved in variable \"scaler\" and handed over to stack model."
   ],
   "id": "fec61fc7d8610c43"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:29:55.829813Z",
     "start_time": "2025-12-10T17:29:55.685022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = HahnParameterScaler() # define scaler\n",
    "\n",
    "# Stack bounds of free parameters\n",
    "free_parameter_bounds = np.vstack([\n",
    "    unscaled_lower_bounds_free_params,\n",
    "    unscaled_upper_bounds_free_params\n",
    "]).T\n",
    "\n",
    "# Stack operating condition bounds (rows = condition, columns = [min, max])\n",
    "operating_condition_bounds = np.vstack([\n",
    "    lower_bounds_operating_conditions,\n",
    "    upper_bounds_operating_conditions\n",
    "]).T\n",
    "\n",
    "# Determine current range for scaling\n",
    "current_bounds = np.array([[I_S_array.min(), I_S_array.max()]])\n",
    "\n",
    "scaled_theta_true = scaler.scale_theta(unscaled_theta_true, free_parameter_bounds)\n",
    "\n",
    "# scale bounds of operating conditions to hand over for Experimental designs incl. LHC\n",
    "scaled_upper_bounds = scaler.scale_params(upper_bounds_operating_conditions, operating_condition_bounds)\n",
    "scaled_lower_bounds = scaler.scale_params(lower_bounds_operating_conditions, operating_condition_bounds)\n",
    "\n",
    "# scale bounds of free parameters for initializing Model\n",
    "scaled_lower_bounds_theta, _ = scaler.scale(unscaled_lower_bounds_free_params, free_parameter_bounds)\n",
    "scaled_upper_bounds_theta, _ = scaler.scale(unscaled_upper_bounds_free_params, free_parameter_bounds)\n",
    "\n",
    "crlb_factor = unscaled_upper_bounds_free_params-unscaled_lower_bounds_free_params # offset for reformating the CRLB\n",
    "unit_factors = np.array([1e-4, 1e4, 1e4]) #[1e-3, 1e-4, 1e4, 1e4, 1e4, 1]) factors to reformat the units from SI to applicable industry standard units\n",
    "\n",
    "# Print scaling results of scaled true parameters\n",
    "print(\"Scaled theta:\", scaled_theta_true)\n",
    "print(\"Rescaled theta:\", unscaled_theta_true)"
   ],
   "id": "e427a24f560e2362",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled theta: [0.42501002 0.00327708 0.8474    ]\n",
      "Rescaled theta: [2.1308e+03 4.2738e-06 8.6266e-06]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define the parametric function including handover of bounds",
   "id": "91441c6aac9119f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:29:55.928834Z",
     "start_time": "2025-12-10T17:29:55.839909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hahn_fc_model = HahnStackModel(parameter_set=HahnParameterSet(free_parameters=names_theta)) #Instantiate the generic Hahn Model\n",
    "calculator = NumericDerivativeCalculator(hahn_fc_model, scaler) #Instantiate the derivation calculator function\n",
    "\n",
    "#Initialize statistical model function\n",
    "statistical_model = FCSGaussianNoiseModel(model_function=hahn_fc_model,\n",
    "                                          der_function=calculator,\n",
    "                                          lower_bounds_x=scaled_lower_bounds,\n",
    "                                          upper_bounds_x=scaled_upper_bounds,\n",
    "                                          lower_bounds_theta=scaled_lower_bounds_theta,\n",
    "                                          upper_bounds_theta=scaled_upper_bounds_theta,\n",
    "                                          sigma=sigma,\n",
    "                                          scaler = scaler,)\n",
    "\n",
    "#Initialize blackbox function returning noised experiment results\n",
    "def blackbox_model(x):\n",
    "    return statistical_model.random(theta=scaled_theta_true, x=x)"
   ],
   "id": "4bed84c12ebec789",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import Base LHC Designs",
   "id": "6320f0d043a8888e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:29:56.032953Z",
     "start_time": "2025-12-10T17:29:55.938909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import_path = \"..\" / Path(\"data\") / \"experimental_designs\" / \"lhc\"\n",
    "df_exp_input = import_experiment_results(import_path/\"lhc.csv\")\n",
    "\n",
    "# prepare LHC data for further analysis\n",
    "x_designs = df_exp_input[['Pressure', 'Temperature', 'Stoichiometry', 'Current']].to_numpy()\n",
    "y_designs = df_exp_input[['Voltage']].to_numpy()\n",
    "\n",
    "# Slice Designs (n=25000) of the repetitions (n=250) for optimal experiment calculation\n",
    "x0_LH_design = x_designs[:number_designs * n_current_values:]"
   ],
   "id": "6b08c55f73d17f9a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## define minimizer for theta estimation on imported experiments",
   "id": "c91ecdc64f8f4ecc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:29:56.217162Z",
     "start_time": "2025-12-10T17:29:56.042558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "iterations = 1000\n",
    "\n",
    "# Without noise, the DE optimizer converges towards theta_true\n",
    "minimizer = DifferentialEvolutionParallel(maxiter=iterations, save_intermediate=True)"
   ],
   "id": "5a642c140fd14c7c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import additional Experiments for optimality criteria",
   "id": "5d6beca81bbb6ac1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:29:56.391701Z",
     "start_time": "2025-12-10T17:29:56.227700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load all_additional experiments (LHC + others)\n",
    "df_all = import_all_experiments(\"..\" / Path(\"data\") / \"experimental_designs\" / \"other\")\n",
    "experiments = {name: group for name, group in df_all.groupby(\"SourceFile\")}"
   ],
   "id": "3940124a257874a9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Designs singular with 5 additional Experiments\n",
    "in total n_number_new_designs (default: 5) * n_current_values * n_rep = 5000"
   ],
   "id": "64890839bc03ecd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:29:56.477671Z",
     "start_time": "2025-12-10T17:29:56.453464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_designs_all = {\n",
    "    \"LH_new\": experiments[\"LH_new\"][['Pressure','Temperature','Stoichiometry','Current']].to_numpy(),\n",
    "    \"a_design\": experiments[\"a_design\"][['Pressure','Temperature','Stoichiometry','Current']].to_numpy(),\n",
    "    \"d_design\": experiments[\"d_design\"][['Pressure','Temperature','Stoichiometry','Current']].to_numpy(),\n",
    "    \"pi_design\": experiments[\"pi_design\"][['Pressure','Temperature','Stoichiometry','Current']].to_numpy(),\n",
    "}\n",
    "\n",
    "y_designs_all = {\n",
    "    \"LH_new\": experiments[\"LH_new\"][['Voltage']].to_numpy(),\n",
    "    \"a_design\": experiments[\"a_design\"][['Voltage']].to_numpy(),\n",
    "    \"d_design\": experiments[\"d_design\"][['Voltage']].to_numpy(),\n",
    "    \"pi_design\": experiments[\"pi_design\"][['Voltage']].to_numpy(),\n",
    "}"
   ],
   "id": "158deacc50eb9f00",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Stack Designs to form 25LHC+5OED Arrays",
   "id": "b3248937bd9b5873"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:29:56.648485Z",
     "start_time": "2025-12-10T17:29:56.489520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.experiment_serialization import combine_experiments\n",
    "\n",
    "cols_x = ['Pressure','Temperature','Stoichiometry','Current']\n",
    "cols_y = ['Voltage']\n",
    "design_names = [\"LH_new\", \"a_design\", \"d_design\", \"pi_design\"]\n",
    "\n",
    "x_designs_all_stacked = {\n",
    "    name: np.vstack([x_designs, experiments[name][cols_x].to_numpy()])\n",
    "    for name in design_names\n",
    "}\n",
    "\n",
    "y_designs_all_stacked = {\n",
    "    name: np.vstack([y_designs, experiments[name][cols_y].to_numpy().reshape(-1, 1)])\n",
    "    for name in design_names\n",
    "}\n",
    "\n",
    "x_designs_all_stacked_new = {\n",
    "    name: combine_experiments(x_designs, experiments[name][cols_x].to_numpy(), n_rep=n_rep)\n",
    "    for name in design_names\n",
    "}\n",
    "\n",
    "y_designs_all_stacked_new = {\n",
    "    name: combine_experiments(y_designs, experiments[name][cols_y].to_numpy().reshape(-1, 1), n_rep=n_rep)\n",
    "    for name in design_names\n",
    "}\n",
    "\n",
    "#test print if the length of the experiment arrays is as expected. should be: (number_designs + n_new_designs) * n_current_values * n_rep\n",
    "for k in x_designs_all_stacked:\n",
    "    print(k, x_designs_all_stacked[k].shape, y_designs_all_stacked[k].shape)\n",
    "\n",
    "for k in x_designs_all_stacked_new:\n",
    "    print(k, x_designs_all_stacked_new[k].shape, y_designs_all_stacked_new[k].shape)"
   ],
   "id": "d88e6d06316b5417",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LH_new (3100, 4) (3100, 1)\n",
      "a_design (3100, 4) (3100, 1)\n",
      "d_design (3100, 4) (3100, 1)\n",
      "pi_design (3100, 4) (3100, 1)\n",
      "LH_new (3100, 4) (3100, 1)\n",
      "a_design (3100, 4) (3100, 1)\n",
      "d_design (3100, 4) (3100, 1)\n",
      "pi_design (3100, 4) (3100, 1)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# All Designs stacked with 25LH + 5 additional Experiments\n",
    "in total (number_designs (default: 25) + n_number_new_designs (default: 5)) * n_current_values * n_rep = 30000"
   ],
   "id": "3c1702072ae6ac16"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-10T17:29:56.661058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_df = evaluate_full_metrics(\n",
    "    statistical_model=statistical_model,\n",
    "    scaled_theta_true=scaled_theta_true,\n",
    "    x_designs=x_designs_all_stacked_new,\n",
    "    y_designs=y_designs_all_stacked_new,\n",
    "    n_rep=n_rep,\n",
    "    minimizer=minimizer,\n",
    "    scaler=scaler,\n",
    ")"
   ],
   "id": "34fc811f458f9ce6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating thetas:   3%|â–Ž         | 3/100 [04:36<2:32:29, 94.32s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:34:43.588021200Z",
     "start_time": "2025-10-18T05:52:39.822362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "crlb_factor = unscaled_upper_bounds_free_params-unscaled_lower_bounds_free_params # offset for reformating the CRLB\n",
    "unit_factors = np.array([1e-4, 1e4, 1e4]) # factors to reformat the units from SI to applicable industry standard units\n",
    "\n",
    "# Rescale parameter-dependent metrics using HahnParameterScaler\n",
    "for idx, row in results_df.iterrows():\n",
    "    est_theta_rescaled = scaler.rescale_theta(row[\"est_theta\"])\n",
    "    diag_CRLB_rescaled = row[\"diag_CRLB\"]*crlb_factor*crlb_factor*unit_factors*unit_factors\n",
    "    crlb_rescaled = row[\"CRLB\"]*crlb_factor*crlb_factor*unit_factors*unit_factors  # matrix diag only\n",
    "\n",
    "    scales = np.array([s.scale_[0] for s in scaler.theta_scalers])\n",
    "    var_theta_rescaled = row[\"var_theta\"] * (scales**2)\n",
    "    std_rescaled = np.sqrt(var_theta_rescaled)\n",
    "\n",
    "    print(f\"\\n=== Experiment: {row['Experiment']} ===\")\n",
    "    print(f\"det(FIM): {row['det_FIM']:.3e}\")\n",
    "    print(f\"est_theta (scaled): {row['est_theta']}\")\n",
    "    print(f\"est_theta (rescaled): {est_theta_rescaled}\")\n",
    "    print(f\"var_theta (scaled): {row['var_theta']}\")\n",
    "    print(f\"var_theta (rescaled): {var_theta_rescaled}\")\n",
    "    print(f\"diag_CRLB (scaled): {row['diag_CRLB']}\")\n",
    "    print(f\"diag_CRLB (rescaled): {diag_CRLB_rescaled}\")\n",
    "    print(f\"standard deviation (rescaled): {std_rescaled}\")\n",
    "    print(f\"rel_std: {row['rel_std']}\")\n",
    "    print(f\"rel_bias: {row['rel_bias']}\")\n",
    "    print(f\"rel_rmse: {row['rel_rmse']}\")"
   ],
   "id": "67da04d5a620cbe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment: LH_new ===\n",
      "det(FIM): 4.021e+13\n",
      "est_theta (scaled): [0.42527443 0.00328335 0.8578292 ]\n",
      "est_theta (rescaled): [2.13211940e+03 4.28006808e-06 8.72046280e-06]\n",
      "var_theta (scaled): [1.49781368e-03 4.46968917e-08 3.57968138e-03]\n",
      "var_theta (rescaled): [6.01529184e-11 4.47864198e-02 4.41935973e+07]\n",
      "diag_CRLB (scaled): [1.29991041e-03 3.62717306e-08 3.60854225e-03]\n",
      "diag_CRLB (rescaled): [3.23678991e-04 3.61992234e-06 2.92291922e-05]\n",
      "standard deviation (rescaled): [7.75583125e-06 2.11628022e-01 6.64782651e+03]\n",
      "rel_std: [0.08477883 0.05800518 0.07002693]\n",
      "rel_bias: [0.00062212 0.00191462 0.01230729]\n",
      "rel_rmse: [0.09060613 0.06421888 0.07132072]\n",
      "\n",
      "=== Experiment: a_design ===\n",
      "det(FIM): 1.214e+16\n",
      "est_theta (scaled): [0.42530186 0.00327814 0.84747514]\n",
      "est_theta (rescaled): [2.13225627e+03 4.27486109e-06 8.62727629e-06]\n",
      "var_theta (scaled): [1.56057869e-03 2.24518219e-08 9.51826498e-06]\n",
      "var_theta (rescaled): [6.26735914e-11 2.24967930e-02 1.17509444e+05]\n",
      "diag_CRLB (scaled): [1.22802705e-03 2.14153975e-08 1.14330874e-05]\n",
      "diag_CRLB (rescaled): [3.05779965e-04 2.13725881e-06 9.26080078e-08]\n",
      "standard deviation (rescaled): [7.91666542e-06 1.49989310e-01 3.42796505e+02]\n",
      "rel_std: [0.08239611 0.04464118 0.00398983]\n",
      "rel_bias: [6.86660725e-04 3.24115875e-04 8.86746221e-05]\n",
      "rel_rmse: [0.09248541 0.04549543 0.00362358]\n",
      "\n",
      "=== Experiment: d_design ===\n",
      "det(FIM): 1.727e+16\n",
      "est_theta (scaled): [0.42241569 0.0032687  0.84723921]\n",
      "est_theta (rescaled): [2.11785427e+03 4.26542842e-06 8.62515292e-06]\n",
      "var_theta (scaled): [1.45960078e-03 2.58978262e-08 9.23998880e-06]\n",
      "var_theta (rescaled): [5.86182699e-11 2.59496997e-02 1.14073936e+05]\n",
      "diag_CRLB (scaled): [1.24589773e-03 2.40264374e-08 7.78136392e-06]\n",
      "diag_CRLB (rescaled): [3.10229781e-04 2.39784085e-06 6.30290478e-08]\n",
      "standard deviation (rescaled): [7.65625692e-06 1.61089105e-01 3.37748332e+02]\n",
      "rel_std: [0.08356053 0.04742092 0.00329247]\n",
      "rel_bias: [-0.00610417 -0.00255714 -0.00018974]\n",
      "rel_rmse: [0.08964882 0.0489279  0.00357419]\n",
      "\n",
      "=== Experiment: pi_design ===\n",
      "det(FIM): 3.349e+15\n",
      "est_theta (scaled): [0.42532128 0.00328256 0.84780527]\n",
      "est_theta (rescaled): [2.13235318e+03 4.27927502e-06 8.63024739e-06]\n",
      "var_theta (scaled): [1.44853443e-03 2.50675520e-08 4.28269010e-05]\n",
      "var_theta (rescaled): [5.81738398e-11 2.51177624e-02 5.28727173e+05]\n",
      "diag_CRLB (scaled): [1.22673645e-03 2.16399273e-08 3.91562101e-05]\n",
      "diag_CRLB (rescaled): [3.05458602e-04 2.15966691e-06 3.17165302e-07]\n",
      "standard deviation (rescaled): [7.62717771e-06 1.58485843e-01 7.27136282e+02]\n",
      "rel_std: [0.08234904 0.04481419 0.00738081]\n",
      "rel_bias: [0.00073236 0.00167238 0.00047825]\n",
      "rel_rmse: [0.08910406 0.0481005  0.00769887]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save Experiment results and theta estimations",
   "id": "60317669863d2a82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:34:43.593201400Z",
     "start_time": "2025-10-18T05:52:39.867638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "# save estimated thetas\n",
    "root = Path.cwd().parent   # this will be oed_fuel_cell_model/\n",
    "data_path = root / \"data\" / \"experimental_designs\" / \"other\"\n",
    "\n",
    "# Save DataFrame\n",
    "results_df.to_pickle(data_path / \"combined_experiments_results_df.pkl\")"
   ],
   "id": "45c92f3c88c84cce",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:40:34.566685Z",
     "start_time": "2025-12-10T17:40:33.502013Z"
    }
   },
   "cell_type": "code",
   "source": "plot_multiple_runs(\"./minimizer_logs/convergence_20251011_061259.csv\")",
   "id": "7cec5041a8f0806f",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './minimizer_logs/convergence_20251011_061259.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mplot_multiple_runs\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m./minimizer_logs/convergence_20251011_061259.csv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FuelCellOED\\src\\visualization\\plotting_convergence.py:19\u001B[39m, in \u001B[36mplot_multiple_runs\u001B[39m\u001B[34m(csv_path, logy, save_path)\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mplot_multiple_runs\u001B[39m(csv_path: \u001B[38;5;28mstr\u001B[39m, logy: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mTrue\u001B[39;00m, save_path: \u001B[38;5;28mstr\u001B[39m = \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m      6\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[33;03m    Plot convergence histories from a CSV file containing multiple runs\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[33;03m    separated by 'final' markers.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     17\u001B[39m \u001B[33;03m        If provided, save the plot to this path instead of showing it.\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m     df = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcsv_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     21\u001B[39m     \u001B[38;5;66;03m# Split into runs using \"final\" markers\u001B[39;00m\n\u001B[32m     22\u001B[39m     runs = []\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FuelCellOED\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FuelCellOED\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FuelCellOED\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FuelCellOED\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\FuelCellOED\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: './minimizer_logs/convergence_20251011_061259.csv'"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
